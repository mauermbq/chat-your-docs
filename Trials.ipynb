{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For allowing langchain to query Wikipedia articles\n",
    "from langchain import Wikipedia\n",
    "\n",
    "#for setting up an enviornmnet in which a ReAct agent can run autonomously\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.react.agent import create_react_agent\n",
    "\n",
    "#For defining tools to give to a language model\n",
    "from langchain.agents import Tool\n",
    "\n",
    "from langchain.agents.react.base import DocstoreExplorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikipedia driver in LangChain is based on the Wikipedia module on PyPi, which is in turn a wrapper of the MediaWiki API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a docstore, and telling the docstore to use LangChains\n",
    "#hook for wikipedia\n",
    "docstore=DocstoreExplorer(Wikipedia())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Helmut Josef Michael Kohl (German pronunciation: [ˈhɛlmuːt ˈkoːl] ; 3 April 1930 – 16 June 2017) was a German politician who served as Chancellor of Germany from 1982 to 1998 and Leader of the Christian Democratic Union (CDU) from 1973 to 1998. Kohl\\'s 16-year tenure is the longest of any German chancellor since Otto von Bismarck, and oversaw the end of the Cold War, the German reunification and the creation of the European Union (EU). Furthermore, Kohl\\'s 16 years and 30-day tenure is the longest for any democratically elected chancellor of Germany.\\nBorn in Ludwigshafen to a Catholic family, Kohl joined the CDU in 1946 at the age of 16. He earned a PhD in history at Heidelberg University in 1958, and worked as a business executive before becoming a full-time politician. He was elected as the youngest member of the Parliament of Rhineland-Palatinate in 1959 and from 1969 to 1976 was minister president of the Rhineland-Palatinate state. Viewed during the 1960s and the early 1970s as a progressive within the CDU, he was elected national chairman of the party in 1973. After he had become party leader, Kohl was increasingly seen as a more conservative figure. In the 1976 and 1980 federal elections his party performed well, but the social-liberal government of social democrat Helmut Schmidt was able to remain in power. After Schmidt had lost the support of the liberal FDP in 1982, Kohl was elected Chancellor through a constructive vote of no confidence, forming a coalition government with the FDP. Kohl chaired the G7 in 1985 and 1992.\\nAs Chancellor, Kohl was committed to European integration and especially to the Franco-German relationship; he was also a steadfast ally of the United States and supported Ronald Reagan\\'s more aggressive policies to weaken the Soviet Union. Following the Revolutions of 1989, his government acted decisively, culminating in the German reunification in 1990. Kohl and French president François Mitterrand were the architects of the Maastricht Treaty which established the EU and the Euro currency. Kohl was also a central figure in the eastern enlargement of the EU, and his government led the effort to push for international recognition of Croatia, Slovenia, and Bosnia and Herzegovina when the states declared independence. He played an instrumental role in resolving the Bosnian War. Domestically Kohl\\'s policies from 1990 focused on integrating former East Germany into reunified Germany, and he moved the federal capital from the \"provisional capital\" Bonn back to Berlin, although he never resided there because the government offices were only relocated in 1999. Kohl also greatly increased federal spending on arts and culture. After his chancellorship, Kohl became honorary chairman of the CDU in 1998 but resigned from the position in 2000 in the wake of the CDU donations scandal which damaged his reputation domestically.\\nKohl received the 1988 Charlemagne Prize and was named Honorary Citizen of Europe by the European Council in 1998. Following his death, Kohl was honoured with the first-ever European act of state in Strasbourg. Kohl was described as \"the greatest European leader of the second half of the 20th century\" by US presidents George H. W. Bush and Bill Clinton.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docstore.search('Helmut Kohl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain Tool\n",
    "\n",
    "A Tool, from LangChain’s perspective, is a function that an agent can use to interact with the world. We can build two tools for our agent, one for search and one for lookup.\n",
    "\n",
    "When the agent wants to use a given tool, it’s referenced by the name field. The func is the actual function that gets called when a tool is used, and the description is an optional but recommended description that allows the model to better understand the tool's purpose.\n",
    "\n",
    "## Agent types\n",
    "\n",
    "In Langchain is a component or module that interacts with the language model, processes inputs, generates outputs, or performs specific tasks within the broader application. The concept of AgentType is used to define and manage different kinds of agents based on their roles, capabilities, or the methods they use.\n",
    "\n",
    "Since version 0.1.0: Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. (see [LangChain create react agent](https://api.python.langchain.com/en/stable/agents/langchain.agents.react.agent.create_react_agent.html#langchain.agents.react.agent.create_react_agent))\n",
    "\n",
    "## Langchain hub\n",
    "\n",
    "Inspired by Hugging Face Hub, [LangChainHub](https://smith.langchain.com) is collection of all artifacts useful for working with LangChain primitives such as prompts, chains and agents. It's a central resource for sharing and discovering high quality prompts, chains and agents that combine together to form complex LLM applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'] template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}'\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "from langchain import hub\n",
    "hprompt = hub.pull(\"hwchase17/react\")\n",
    "print(hprompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=docstore.search,\n",
    "        description=\"useful for when you need to ask with search\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Lookup\",\n",
    "        func=docstore.lookup,\n",
    "        description=\"useful for when you need to ask with lookup\"\n",
    "    )\n",
    "]\n",
    "\n",
    "prompt = \"What is the age of the president of the United States? The current date is Dec 26 2023.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReAct Agent\n",
    "\n",
    "The prompt must have input keys:\n",
    "tools: contains descriptions and arguments for each tool.\n",
    "tool_names: contains all tool names.\n",
    "agent_scratchpad: contains previous agent actions and tool outputs as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = '''Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}'''\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", openai_api_key=\"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\")\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/2q/0d84nxdx5vs59dmrwvkdmzch0000gn/T/ipykernel_53284/2333949846.py\", line 1, in <module>\n",
      "    agent_executor.invoke({\"input\": \"hi\"})\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/langchain/chains/base.py\", line 89, in invoke\n",
      "    \"\"\"Optional list of tags associated with the chain. Defaults to None.\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/langchain/chains/base.py\", line 312, in __call__\n",
      "    A dict of named outputs. Should contain all outputs specified in\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/langchain/chains/base.py\", line 306, in __call__\n",
      "    inputs: A dict of named inputs to the chain. Assumed to contain all inputs\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/langchain/agents/agent.py\", line 1312, in _call\n",
      "    )\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/langchain/agents/agent.py\", line 1038, in _take_next_step\n",
      "    def _should_continue(self, iterations: int, time_elapsed: float) -> bool:\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/langchain/agents/agent.py\", line 1038, in <listcomp>\n",
      "    def _should_continue(self, iterations: int, time_elapsed: float) -> bool:\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/langchain/agents/agent.py\", line 1066, in _iter_next_step\n",
      "    run_manager: Optional[AsyncCallbackManagerForChainRun] = None,\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/langchain/agents/agent.py\", line 385, in plan\n",
      "    # accumulate the output into final output and return that.\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 1514, in invoke\n",
      "    if final_input is None:\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 2937, in invoke\n",
      "    **kwargs: Any,\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/llms.py\", line 226, in invoke\n",
      "    **kwargs: Any,\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/llms.py\", line 516, in generate_prompt\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/llms.py\", line 666, in generate\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/llms.py\", line 553, in _generate_helper\n",
      "    run_manager=run_managers[0] if run_managers else None,\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_core/language_models/llms.py\", line 540, in _generate_helper\n",
      "    self,\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_community/llms/openai.py\", line 459, in _generate\n",
      "    else:\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_community/llms/openai.py\", line 122, in completion_with_retry\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/tenacity/__init__.py\", line 289, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/tenacity/__init__.py\", line 379, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/tenacity/__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/tenacity/__init__.py\", line 382, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/langchain_community/llms/openai.py\", line 120, in _completion_with_retry\n",
      "    def _completion_with_retry(**kwargs: Any) -> Any:\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/openai/api_resources/completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/openai/api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.AuthenticationError: Incorrect API key provided: sk-OCVwq***************************************shpy. You can find your API key at https://platform.openai.com/account/api-keys.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ellipsis' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m hub\u001b[38;5;241m.\u001b[39mpull(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhwchase17/react\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m llm \u001b[38;5;241m=\u001b[39m OpenAI(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m, openai_api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msk-OCVwqHPca60YG0Dkevu3T3BlbkFJrilEdgczczguRaTAshpy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_react_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m agent_executor \u001b[38;5;241m=\u001b[39m AgentExecutor(agent\u001b[38;5;241m=\u001b[39magent, tools\u001b[38;5;241m=\u001b[39mtools)\n\u001b[1;32m      7\u001b[0m agent_executor\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhi\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[0;32m/opt/dev/miniconda3/envs/llm/lib/python3.10/site-packages/langchain/agents/react/agent.py:100\u001b[0m, in \u001b[0;36mcreate_react_agent\u001b[0;34m(llm, tools, prompt)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_vars:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt missing required variables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_vars\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m prompt \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[0;32m--> 100\u001b[0m     tools\u001b[38;5;241m=\u001b[39mrender_text_description(\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m),\n\u001b[1;32m    101\u001b[0m     tool_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([t\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tools]),\n\u001b[1;32m    102\u001b[0m )\n\u001b[1;32m    103\u001b[0m llm_with_stop \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mObservation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    104\u001b[0m agent \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    105\u001b[0m     RunnablePassthrough\u001b[38;5;241m.\u001b[39massign(\n\u001b[1;32m    106\u001b[0m         agent_scratchpad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: format_log_to_str(x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintermediate_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;241m|\u001b[39m ReActSingleInputOutputParser()\n\u001b[1;32m    111\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ellipsis' object is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "model = llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", openai_api_key=\"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\")\n",
    "\n",
    "agent = create_react_agent(model, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"hi\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
